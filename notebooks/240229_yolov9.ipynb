{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/niche/COLO/yolov9\")\n",
    "os.getcwd()\n",
    "from pyniche.trainer import NicheTrainer\n",
    "from pyniche.models.detection.yolo import NicheYOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATA = \"data/1a_angle_t2s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = NicheTrainer() \n",
    "trainer.type = \"yolo\"\n",
    "trainer.set_data(\n",
    "        dataclass=DIR_DATA,\n",
    "        batch=16,\n",
    "        n=128,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/niche/COLO/yolov9/train_dual.py\", line 12, in <module>\r\n",
      "    import torch\r\n",
      "  File \"/home/niche/.conda/envs/tf/lib/python3.9/site-packages/torch/__init__.py\", line 1476, in <module>\r\n",
      "    from torch import func as func\r\n",
      "  File \"/home/niche/.conda/envs/tf/lib/python3.9/site-packages/torch/func/__init__.py\", line 1, in <module>\r\n",
      "    from torch._functorch.eager_transforms import (\r\n",
      "  File \"/home/niche/.conda/envs/tf/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py\", line 12, in <module>\r\n",
      "    from torch.fx.experimental import const_fold\r\n",
      "  File \"/home/niche/.conda/envs/tf/lib/python3.9/site-packages/torch/fx/experimental/const_fold.py\", line 6, in <module>\r\n",
      "    from torch.fx.passes.split_module import split_module\r\n",
      "  File \"/home/niche/.conda/envs/tf/lib/python3.9/site-packages/torch/fx/passes/__init__.py\", line 3, in <module>\r\n",
      "    from . import net_min_base\r\n",
      "  File \"/home/niche/.conda/envs/tf/lib/python3.9/site-packages/torch/fx/passes/net_min_base.py\", line 11, in <module>\r\n",
      "    from .split_utils import split_by_tags\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 846, in exec_module\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 941, in get_code\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1039, in get_data\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!python3.9 train_dual.py \\\n",
    "--batch 16 --epochs 20 --img 640 --device 0 --min-items 0 --close-mosaic 15 \\\n",
    "--data data/1a_angle_t2s/data.yaml\\\n",
    "--weights yolov9-c.pt\\\n",
    "--cfg models/detect/yolov9-c.yaml\\\n",
    "--hyp data/hyps/hyp.scratch-high.yaml\\\n",
    "--project .\\\n",
    "--name out/yolov9/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval_dual: \u001b[0mdata=data/1a_angle_t2s/data.yaml, weights=['out/yolov9/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.45, iou_thres=0.7, max_det=300, task=test, device=0, workers=8, single_cls=True, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=., name=out/yolov9/eval, exist_ok=False, half=False, dnn=False, min_items=0\n",
      "WARNING ⚠️ confidence threshold 0.45 > 0.001 produces invalid results\n",
      "YOLOv5 🚀 2024-2-29 Python-3.9.16 torch-2.0.1+cu117 CUDA:0 (NVIDIA A100-SXM4-80GB, 81251MiB)\n",
      "\n",
      "Fusing layers... \n",
      "yolov9-c summary: 604 layers, 50698278 parameters, 0 gradients, 236.6 GFLOPs\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning /home/niche/COLO/yolov9/data/1a_angle_t2s/test.cache... 50 images\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         50        709      0.749      0.354      0.576      0.373\n",
      "Speed: 0.2ms pre-process, 10.9ms inference, 1.4ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mout/yolov9/eval2\u001b[0m\n",
      "50 labels saved to out/yolov9/eval2/labels\n"
     ]
    }
   ],
   "source": [
    "!python3.9 val_dual.py \\\n",
    "--weights out/yolov9/weights/best.pt\\\n",
    "--device 0\\\n",
    "--data data/1a_angle_t2s/data.yaml\\\n",
    "--task test\\\n",
    "--project .\\\n",
    "--name out/yolov9/eval\\\n",
    "--save-txt\\\n",
    "--save-conf\\\n",
    "--single-cls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A class to organize YOLO-structured data\n",
    "\n",
    "Methods\n",
    "---\n",
    "\n",
    "get_images\n",
    "    list of absolute paths of images in root/<split>/images\n",
    "clone\n",
    "    copy root/train and root/test to root/<folder_name>\n",
    "shuffle_train_val\n",
    "    shuffle self.ls_train_images and assign to\n",
    "save_yaml\n",
    "save_txt\n",
    "\n",
    "\n",
    "Folder structure\n",
    "---\n",
    "root/\n",
    "    train/ (required)\n",
    "        images/\n",
    "            img_1_13_jpg.rf.d69528304f2d10b633c6d94982185cb2.jpg\n",
    "            img_2_13_jpg.rf.d69528304f2d10b633c6d94982185cb2.jpg\n",
    "            ...\n",
    "        labels/\n",
    "            img_1_13_jpg.rf.d69528304f2d10b633c6d94982185cb2.txt\n",
    "            img_2_13_jpg.rf.d69528304f2d10b633c6d94982185cb2.txt\n",
    "            ...\n",
    "    test/ (required)\n",
    "        images/\n",
    "            img_3.jpg\n",
    "            img_4.jpg\n",
    "            ...\n",
    "        labels/\n",
    "            img_3.txt\n",
    "            img_4.txt\n",
    "\n",
    "    test.txt (generated)\n",
    "    train.txt (generated)\n",
    "    val.txt (generated)\n",
    "    data.yaml (generated)\n",
    "\n",
    "Example YAML\n",
    "---\n",
    "path: /home/niche/cowsformer/data/cow200/yolov5/run3\n",
    "train: \"train.txt\"\n",
    "val: \"val.txt\"\n",
    "test: \"test.txt\"\n",
    "names:\n",
    "  0: none\n",
    "  1: cow\n",
    "\n",
    "Example train.txt\n",
    "---\n",
    "\n",
    "/home/niche/cowsformer/data/cow200/yolov5/run0/images/img_32_jpg\n",
    "/home/niche/cowsformer/data/cow200/yolov5/run0/images/img_1_jpg\n",
    "/home/niche/cowsformer/data/cow200/yolov5/run0/images/img_1_26_jpg\n",
    "/home/niche/cowsformer/data/cow200/yolov5/run0/images/img_1_62_jpg\n",
    "/home/niche/cowsformer/data/cow200/yolov5/run0/images/img_1_10_jpg\n",
    "/home/niche/cowsformer/data/cow200/yolov5/run0/images/img_3_11_jpg\n",
    "/home/niche/cowsformer/data/cow200/yolov5/run0/images/img_4_3_jpg\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import PIL\n",
    "import torch\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "# local imports\n",
    "from pyniche.data.bbox import xywh2xyxy\n",
    "\n",
    "\n",
    "class YOLO_API:\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "    ):\n",
    "        self.root = root\n",
    "        self.ls_train_images_all = self.get_images(\"train\")\n",
    "        self.ls_train_images = None\n",
    "        self.ls_val_iamges = None\n",
    "        self.ls_test_images = self.get_images(\"test\")\n",
    "        self.save_txt(\"test\")\n",
    "\n",
    "    def get_PIL(self, split, idx):\n",
    "        \"\"\"\n",
    "        get PIL image from split and idx\n",
    "\n",
    "        params\n",
    "        ------\n",
    "        split: str\n",
    "            \"train\" or \"test\"\n",
    "        idx: int\n",
    "            index of the image\n",
    "\n",
    "        return\n",
    "        ------\n",
    "        PIL.Image\n",
    "        \"\"\"\n",
    "        if split == \"train\":\n",
    "            path = self.ls_train_images_all[idx]\n",
    "        else:\n",
    "            path = self.ls_test_images[idx]\n",
    "        return PIL.Image.open(path)\n",
    "\n",
    "    def get_images(self, split):\n",
    "        \"\"\"\n",
    "        search images names (.jpg) in root/<split>/images\n",
    "\n",
    "        params\n",
    "        ------\n",
    "        split: str\n",
    "            \"train\" or \"test\"\n",
    "\n",
    "        return\n",
    "        ------\n",
    "        a list of aboslute paths of images\n",
    "        \"\"\"\n",
    "        return self.get_filepaths(split, \"images\")\n",
    "\n",
    "    def get_labels(self, split):\n",
    "        \"\"\"\n",
    "        search label names (.txt) in root/<split>/labels\n",
    "\n",
    "        params\n",
    "        ------\n",
    "        split: str\n",
    "            \"train\" or \"test\"\n",
    "\n",
    "        return\n",
    "        ------\n",
    "        a list of aboslute paths of labels\n",
    "        \"\"\"\n",
    "        return self.get_filepaths(split, \"labels\")\n",
    "\n",
    "    def get_filepaths(self, split, folder):\n",
    "        \"\"\"\n",
    "        get file paths of images or labels\n",
    "\n",
    "        params\n",
    "        ---\n",
    "        split: str\n",
    "            \"train\" or \"test\"\n",
    "        folder: str\n",
    "            \"images\" or \"labels\"\n",
    "        \"\"\"\n",
    "        path_files = os.path.join(self.root, split, folder)\n",
    "        ext = \".jpg\" if folder == \"images\" else \".txt\"\n",
    "        ls_files = [f for f in os.listdir(path_files) if f.endswith(ext)]\n",
    "        ls_files = [os.path.join(path_files, f) for f in ls_files]\n",
    "        return sorted(ls_files)\n",
    "\n",
    "    def get_detections(self, split, path_preds=None):\n",
    "        \"\"\"\n",
    "        get sv.Detections from labels\n",
    "\n",
    "        params\n",
    "        ------\n",
    "        split: str\n",
    "            \"train\" or \"test\"\n",
    "        path_results: str\n",
    "            path to the dir of predictions (.txt). If provided, the detections will be\n",
    "            created from the predictions, and the format will be\n",
    "            [class_id, x_center, y_center, width, height, confidence].\n",
    "            Otherwise, from the labels.\n",
    "\n",
    "        return\n",
    "        ------\n",
    "        a list of sv.Detections\n",
    "        \"\"\"\n",
    "        detections = []\n",
    "        # get file paths\n",
    "        if path_preds:\n",
    "            labels = [f for f in os.listdir(path_preds) if f.endswith(\".txt\")]\n",
    "            labels = sorted([os.path.join(path_preds, f) for f in labels])\n",
    "        else:\n",
    "            labels = self.get_labels(split)\n",
    "        images = self.get_images(split)\n",
    "        n_samples = len(images)\n",
    "        # iterate each pair of image and label\n",
    "        for i in range(n_samples):\n",
    "            # get image info\n",
    "            image = PIL.Image.open(images[i])\n",
    "            img_w, img_h = image.size\n",
    "            # get annotation\n",
    "            label = labels[i]\n",
    "            with open(label, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                lines = [l.strip() for l in lines]\n",
    "            # each detection in the image/label\n",
    "            ls_xyxy = []\n",
    "            ls_cls = []\n",
    "            ls_conf = []\n",
    "            for l in lines:\n",
    "                parts = l.split(\" \")\n",
    "                class_id = int(parts[0])\n",
    "                coords = tuple(\n",
    "                    map(float, parts[1:5])\n",
    "                )  # x_center, y_center, width, height\n",
    "                conf = float(parts[5]) if path_preds else None\n",
    "                xyxy = xywh2xyxy(\n",
    "                    coords,\n",
    "                    img_size=(img_w, img_h),\n",
    "                )\n",
    "                # append to lists\n",
    "                ls_xyxy.append(xyxy)\n",
    "                ls_cls.append(class_id)\n",
    "                if path_preds:\n",
    "                    ls_conf.append(conf)\n",
    "            # create sv.Detections\n",
    "            ls_xyxy = torch.stack(ls_xyxy).numpy()\n",
    "            ls_cls = np.array(ls_cls)\n",
    "            ls_conf = np.array(ls_conf)\n",
    "            detection = sv.Detections(\n",
    "                ls_xyxy,\n",
    "                class_id=ls_cls,\n",
    "                confidence=ls_conf if path_preds else None,\n",
    "            )\n",
    "            detections.append(detection)\n",
    "        return detections\n",
    "\n",
    "    def clone(self, folder_name):\n",
    "        \"\"\"\n",
    "        copy root/train and root/test to\n",
    "        root/<folder_name>/train and root/<folder_name>/test\n",
    "        \"\"\"\n",
    "        path_train = os.path.join(self.root, \"train\")\n",
    "        path_test = os.path.join(self.root, \"test\")\n",
    "        path_folder = os.path.join(self.root, folder_name)\n",
    "        if os.path.exists(path_folder):\n",
    "            shutil.rmtree(path_folder)\n",
    "        os.mkdir(path_folder)\n",
    "        shutil.copytree(path_train, os.path.join(path_folder, \"train\"))\n",
    "        shutil.copytree(path_test, os.path.join(path_folder, \"test\"))\n",
    "        # copy yaml and other txt\n",
    "        shutil.copy(os.path.join(self.root, \"data.yaml\"), path_folder)\n",
    "        shutil.copy(os.path.join(self.root, \"train.txt\"), path_folder)\n",
    "        shutil.copy(os.path.join(self.root, \"test.txt\"), path_folder)\n",
    "\n",
    "    def shuffle_train_val(self, n=None, k=5):\n",
    "        \"\"\"\n",
    "        shuffle self.ls_train_images and assign to\n",
    "        self.ls_train_images and self.ls_val_images\n",
    "\n",
    "        params\n",
    "        ------\n",
    "        n: None or int or float\n",
    "            None: use all images\n",
    "            int: number of images to be included in the train/val set\n",
    "            float: ratio of images to be included in the train/val set\n",
    "        k: int\n",
    "            how many folds to split the train/val set\n",
    "        \"\"\"\n",
    "        # determine n\n",
    "        total_n = len(self.ls_train_images_all)\n",
    "        if n is None:\n",
    "            n = total_n\n",
    "        elif isinstance(n, float):\n",
    "            n = int(n * total_n)\n",
    "        n_val = int(n / k)\n",
    "        # shuffle training images\n",
    "        random.shuffle(self.ls_train_images_all)\n",
    "        train_images = self.ls_train_images_all[:n]\n",
    "        # split train/val\n",
    "        self.ls_train_images = train_images[:-n_val]\n",
    "\n",
    "        self.ls_val_images = train_images[-n_val:]\n",
    "        self.save_txt(\"train\")\n",
    "        self.save_txt(\"val\")\n",
    "\n",
    "    def save_yaml(self, classes, name=\"data.yaml\"):\n",
    "        \"\"\"\n",
    "        make data.yaml in root\n",
    "\n",
    "        params\n",
    "        ------\n",
    "        classes: list\n",
    "            e.g., [\"cow\", \"none\"]\n",
    "\n",
    "        name: str\n",
    "            name of the yaml file\n",
    "\n",
    "        \"\"\"\n",
    "        path_yaml = os.path.join(self.root, name)\n",
    "        with open(path_yaml, \"w\") as f:\n",
    "            f.write(f\"path: {self.root}\\n\")\n",
    "            f.write(f'train: \"train.txt\"\\n')\n",
    "            f.write(f'val: \"val.txt\"\\n')\n",
    "            f.write(f'test: \"test.txt\"\\n')\n",
    "            f.write(\"names:\\n\")\n",
    "            for i, c in enumerate(classes):\n",
    "            t    f.write(f\"  {i}: {c}\\n\")\n",
    "\n",
    "    def save_txt(self, split):\n",
    "        \"\"\"\n",
    "        save <split>.txt in root\n",
    "        \"\"\"\n",
    "        path_txt = os.path.join(self.root, f\"{split}.txt\")\n",
    "        with open(path_txt, \"w\") as f:\n",
    "            for img in getattr(self, f\"ls_{split}_images\"):\n",
    "                f.write(img + \"\\n\")\n",
    "\n",
    "    def path_yaml(self):\n",
    "        return os.path.join(self.root, \"data.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(None, dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyniche.data.yolo.API import YOLO_API\n",
    "api = YOLO_API(DIR_DATA)\n",
    "lbs = api.get_detections(\"test\")\n",
    "pre = api.get_detections(\"test\", path_preds=\"out/yolov9/eval2/labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map5095': 0.3725151422749049, 'map50': 0.5756328291933566, 'precision': 0.7731343283582089, 'recall': 0.36530324400564174, 'f1': 0.4961685823754789, 'n_all': 50, 'n_fn': 450, 'n_fp': 76}\n"
     ]
    }
   ],
   "source": [
    "from pyniche.evaluate import from_sv\n",
    "out = from_sv(pre, lbs)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
