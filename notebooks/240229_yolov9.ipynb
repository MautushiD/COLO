{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/niche/COLO/yolov9\")\n",
    "os.getcwd()\n",
    "from pyniche.trainer import NicheTrainer\n",
    "from pyniche.models.detection.yolo import NicheYOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATA = \"data/1a_angle_t2s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = NicheTrainer() \n",
    "trainer.type = \"yolo\"\n",
    "trainer.set_data(\n",
    "        dataclass=DIR_DATA,\n",
    "        batch=16,\n",
    "        n=128,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/niche/COLO/yolov9/train_dual.py\", line 12, in <module>\r\n",
      "    import torch\r\n",
      "  File \"/home/niche/.conda/envs/tf/lib/python3.9/site-packages/torch/__init__.py\", line 1476, in <module>\r\n",
      "    from torch import func as func\r\n",
      "  File \"/home/niche/.conda/envs/tf/lib/python3.9/site-packages/torch/func/__init__.py\", line 1, in <module>\r\n",
      "    from torch._functorch.eager_transforms import (\r\n",
      "  File \"/home/niche/.conda/envs/tf/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py\", line 12, in <module>\r\n",
      "    from torch.fx.experimental import const_fold\r\n",
      "  File \"/home/niche/.conda/envs/tf/lib/python3.9/site-packages/torch/fx/experimental/const_fold.py\", line 6, in <module>\r\n",
      "    from torch.fx.passes.split_module import split_module\r\n",
      "  File \"/home/niche/.conda/envs/tf/lib/python3.9/site-packages/torch/fx/passes/__init__.py\", line 3, in <module>\r\n",
      "    from . import net_min_base\r\n",
      "  File \"/home/niche/.conda/envs/tf/lib/python3.9/site-packages/torch/fx/passes/net_min_base.py\", line 11, in <module>\r\n",
      "    from .split_utils import split_by_tags\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 846, in exec_module\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 941, in get_code\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1039, in get_data\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!python3.9 train_dual.py \\\n",
    "--batch 16 --epochs 20 --img 640 --device 0 --min-items 0 --close-mosaic 15 \\\n",
    "--data data/1a_angle_t2s/data.yaml\\\n",
    "--weights yolov9-c.pt\\\n",
    "--cfg models/detect/yolov9-c.yaml\\\n",
    "--hyp data/hyps/hyp.scratch-high.yaml\\\n",
    "--project .\\\n",
    "--name out/yolov9/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval_dual: \u001b[0mdata=data/1a_angle_t2s/data.yaml, weights=['out/yolov9/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.45, iou_thres=0.7, max_det=300, task=test, device=0, workers=8, single_cls=True, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=., name=out/yolov9/eval, exist_ok=False, half=False, dnn=False, min_items=0\n",
      "WARNING ⚠️ confidence threshold 0.45 > 0.001 produces invalid results\n",
      "YOLOv5 🚀 2024-2-29 Python-3.9.16 torch-2.0.1+cu117 CUDA:0 (NVIDIA A100-SXM4-80GB, 81251MiB)\n",
      "\n",
      "Fusing layers... \n",
      "yolov9-c summary: 604 layers, 50698278 parameters, 0 gradients, 236.6 GFLOPs\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning /home/niche/COLO/yolov9/data/1a_angle_t2s/test.cache... 50 images\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         50        709      0.749      0.354      0.576      0.373\n",
      "Speed: 0.2ms pre-process, 10.9ms inference, 1.4ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mout/yolov9/eval2\u001b[0m\n",
      "50 labels saved to out/yolov9/eval2/labels\n"
     ]
    }
   ],
   "source": [
    "!python3.9 val_dual.py \\\n",
    "--weights out/yolov9/weights/best.pt\\\n",
    "--conf 0.45 --iou 0.7 --device 0\\\n",
    "--data data/1a_angle_t2s/data.yaml\\\n",
    "--task test\\\n",
    "--project .\\\n",
    "--name out/yolov9/eval\\\n",
    "--save-txt\\\n",
    "--save-conf\\\n",
    "--single-cls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
